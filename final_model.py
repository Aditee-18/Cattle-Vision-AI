# -*- coding: utf-8 -*-
"""final model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/156eTvStX67odK3F7nvF4ZiD9AL2LJXpF
"""

import os
import zipfile
from google.colab import drive

# 1. Connect Google Drive
drive.mount('/content/drive')

# 2. Path to your zip on Drive (Assuming it is simply 'images.zip')
zip_path = '/content/drive/MyDrive/images/images.zip'
extract_path = '/content/dataset_final'

# 3. Unzip
if not os.path.exists(zip_path):
    print("‚ùå ERROR: Could not find 'images.zip' in your Drive/images folder.")
    print("Please check if the file path is exactly: " + zip_path)
else:
    print("‚è≥ Unzipping...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

    # 4. Auto-Detect where the cow folders are
    DATA_DIR = extract_path
    found = False
    for root, dirs, files in os.walk(extract_path):
        # We look for a known breed to confirm this is the right folder
        if "Murrah" in dirs or "Gir" in dirs:
            DATA_DIR = root
            found = True
            break

    if found:
        print(f"‚úÖ Success! Data Folder found at: {DATA_DIR}")
        # Save path for next block
        os.environ['FINAL_DATA_PATH'] = DATA_DIR
    else:
        print("‚ùå ERROR: Unzipped successfully, but couldn't find breed folders inside.")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import os

# 1. Get Path from Block 1
DATA_DIR = os.environ.get('FINAL_DATA_PATH')
IMG_SIZE = (224, 224)
BATCH_SIZE = 16

print(f"üöÄ Preparing to Train on Data from: {DATA_DIR}")

# 2. Data Generators (No /255 division!)
train_datagen = ImageDataGenerator(
    rescale=None,           # EfficientNet handles math internally
    validation_split=0.2,   # 80/20 split
    rotation_range=30,      # Help AI see angled horns
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_directory(
    DATA_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', subset='training', shuffle=True
)

validation_generator = train_datagen.flow_from_directory(
    DATA_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', subset='validation', shuffle=False
)

# 3. Build Model (Fine-Tuning Setup)
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Unfreeze top 30 layers to learn horn shapes
base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.4)(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# 4. Compile (Low Learning Rate for precision)
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy', metrics=['accuracy'])

# 5. Start Training
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)

print("üî• Training Started...")
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=40, # Max limit (Early Stop will cut it short)
    callbacks=[early_stop, reduce_lr]
)
print("‚úÖ Training Finished.")

import shutil

# Define the filename
FINAL_MODEL_NAME = 'cattle_final_v3.h5'

# 1. Save to Colab Disk
model.save(FINAL_MODEL_NAME)
print(f"‚úÖ Model saved to Colab as: {FINAL_MODEL_NAME}")

# 2. Copy to Google Drive (Backup)
drive_dest = f'/content/drive/MyDrive/{FINAL_MODEL_NAME}'
shutil.copy(FINAL_MODEL_NAME, drive_dest)
print(f"‚úÖ Model backed up to Google Drive at: {drive_dest}")

# 3. Trigger Browser Download
from google.colab import files
files.download(FINAL_MODEL_NAME)
print("‚¨áÔ∏è Download starting...")

# 4. Print Dictionary for your App (Just in case)
print("\nüëá UPDATE YOUR PYTHON APP WITH THIS LIST üëá")
print(train_generator.class_indices)